{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "Rsv0MggUx9vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "f2wYh8Q3x9xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height, img_width = (28,28)\n",
        "\n",
        "train_data_dir = r\"/content/drive/My Drive/train\"\n",
        "test_data_dir = r\"/content/drive/My Drive/test\""
      ],
      "metadata": {
        "id": "HUb1S7-ex9z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a data generator\n",
        "datagen = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "aEenxOi6x92Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(28, 28),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=1000,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "uPeLS6Xfx95V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(28, 28),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=500,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "CqJop3K8x98D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i deducted the batch size of both training and testing set to 1000 and 500 the reason was that it was takinng a lot of time and i did not had enough time it took more than 30mins and still didn't run"
      ],
      "metadata": {
        "id": "5-Xzd181zase"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test,y_test = test_generator.next()\n",
        "X_train, y_train = train_generator.next()"
      ],
      "metadata": {
        "id": "uOqBCFNLx9-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape\n"
      ],
      "metadata": {
        "id": "zd3dTKKTDEYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')"
      ],
      "metadata": {
        "id": "HQRRzUPXw9Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "_wiLpEo-x-Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode outputs\n",
        "#y_train = np_utils.to_categorical(y_train)\n",
        "#y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "y_train.shape"
      ],
      "metadata": {
        "id": "jCHHfJ2_x-H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(784, input_dim=784, kernel_initializer='normal', activation='sigmoid'))\n",
        "\tmodel.add(Dense(512, activation='sigmoid'))\n",
        "\tmodel.add(Dense(312, activation='sigmoid'))\n",
        "\tmodel.add(Dense(10, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "CnfCMjdyx-Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fl7ggpvZuF1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
        "model.fit(x=X_train,y=y_train, epochs=350)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "delq9XMg2RH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the model sir used while solving confusions in the assignment i will now tune its hyperparameters and change its optimizations to check how it performs,  by startinnng off i changed the activation function from sigmoid to relu"
      ],
      "metadata": {
        "id": "J6jar3zNy3dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(784, input_dim=784, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(312, activation='relu'))\n",
        "\tmodel.add(Dense(524, activation='relu'))\n",
        "\tmodel.add(Dense(10, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "1a3atzahuF6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-0Ratw8XuF94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
        "model.fit(x=X_train,y=y_train, epochs=350)"
      ],
      "metadata": {
        "id": "yUrltNfXuBNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "67i2-eCIuFFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "base line error is still 18.60% now i will change the optimization function and use stochastic gradient decent sgd instead of adam and see how it performes"
      ],
      "metadata": {
        "id": "d20oizLpviyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(784, input_dim=784, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(512, activation='relu'))\n",
        "\tmodel.add(Dense(312, activation='relu'))\n",
        "\tmodel.add(Dense(10, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "_K6CyvkPu4RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lfpzk0fGyLb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
        "model.fit(x=X_train,y=y_train, epochs=350)"
      ],
      "metadata": {
        "id": "8wMWydmSvYKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "Kn-Xu85_vdce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the basline error shows a slight decrease as compared to adams optimizer SGD performed well"
      ],
      "metadata": {
        "id": "VXibe_vav-fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(784, input_dim=784, kernel_initializer='normal', activation='relu'))\n",
        "\tmodel.add(Dense(612, activation='relu'))\n",
        "\tmodel.add(Dense(312, activation='relu'))\n",
        "\tmodel.add(Dense(10, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "REwcCSnUweuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GHv8SBxkyRqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
        "model.fit(x=X_train,y=y_train, epochs=350)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "7T0msKJqwln0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the RMSprop performed better than both adam and SGD"
      ],
      "metadata": {
        "id": "AKbpym7FxzMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hoX3yC9_x6zB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "number recognition using MLP.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}